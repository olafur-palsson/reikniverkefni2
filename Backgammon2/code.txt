#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
A class implementation of backgammon.

NOTE:
Player 1 is defined as the player who has the first turn.
Think of player 1 as the current player.

If add a mechanism in the beginning of the game such that each player rolls
to determine who's to the play, then it might be necessar to flip the board.


TODO: it would be cool if it were possible to hot-swap players, i.e. in the
middle of a game swap one player (e.g. some neural network player) for a
human player.

TODO: add ability to support human players.  So both players can be occupied
by huamsn.

TODO: add the ability to record an episode.  We could possibly generate
episodes generated by humans, and use off-pub_stomper_policy training to train other
pub_stomper_agents.
"""
import numpy as np
from pathlib import Path
import random



def str_symbol(board, pos, height):
    """
    A helper class for the string representation for `Backgammon`.

    Args:
        board (ndarray): backgammon board
        pos (int): ?
        height: (int) ?

    Returns:
        Symbols "x", "o" or " ".
    """

    if abs(board[pos]) > height:
        if board[pos] > 0:
            # White
            return "x"
        else:
            # Black
            return "o"
    else:
        return " "


class Backgammon:
    """
    Implementation of Backgammon.

    This implementation makes no assumption about the player, i.e. whether
    the player is a computer controlled bot or a human player.
    """

    PLAYER_1_SYMBOL = "x"
    PLAYER_2_SYMBOL = "o"

    def __init__(self):
        """
        Notice: when the player is asked for an `action` that player always
        sees him-/herself as player nr. 1

        NOTE: I'm not sure about that, go over it.

        Player 1 has the number `1` (positive) and is denoted as `x`

        Player 2 has the number `-1` (negative) and is denoted as `o`.
        """
        self.board = np.zeros(0)  # Just to get type information

        self.player_1 = None  # TODO: make instance of future interface
        self.player_2 = None  # TODO: make instance of future interface

        # `1` for player 1 and `-1` for player 2
        self.active_player = 0  # Just to get type information

        self.reset()


    def set_player_1(self, player):
        """
        Sets player 1 to `player`.

        Args:
            player: ?
        """
        self.player_1 = player


    def set_player_2(self, player):
        """
        Sets player 2 to `player`.

        Args:
            player: ?
        """
        self.player_2 = player


    def reset(self):
        """
        Initializes the board and resets everything to default.
        """
        # Create board and initialize it

        #
        # Meaning of array.
        #
        # o: -
        # x: +
        #
        #    <-- x --                                       -- o -->
        # ? .-------------.-------------.-------------.-------------.
        # ? |           x |           o | x           | o           | J J O O
        # ? |           x |           o | x           | o           | 1 2 1 2
        # ? |           x |   x       o | x       o   | o           |
        # ? | o         x |   x       o | x       o   | o         x | J J O O
        # ? | o         x |   x       o | x       o   | o         x | 1 2 1 2
        # ? '-^-^-^-^-^-^-'-^-^-^-^-^-^-'-^-^-^-^-^-^-'-^-^-^-^-^-^-'
        #                         1 1 1   1 1 1 1 1 1   1 2 2 2 2 2   2 2 2 2
        # 0   1 2 3 4 5 6   7 8 9 0 1 2   3 4 5 6 7 8   9 0 1 2 3 4   5 6 7 8
        #
        # Where ? means I don't know what that means.
        #
        # J1 is jail 1
        # J2 is jail 2
        #
        # O1 is off 1
        # O2 is off 2
        #
        #


        # board[0]  unknown

        self.board = np.zeros(29)
        self.board[1] = -2
        self.board[6] = 5
        self.board[8] = 3
        self.board[12] = -5
        self.board[13] = 5
        self.board[17] = -3
        self.board[19] = -5
        self.board[24] = 2

        # board[25]  jail for player 1
        # board[26]  jail for player 2
        # board[27]  off-ed checkers for player 1
        # board[28]  off-ed checkers for player 2

        # Reset active player
        # `1` for player 1 and `-1` for player 2
        self.active_player = 0  # Just to get type information


    def roll_dice(self):
        """
        Rolls the dice, i.e. creates two numbers, each number is sampled
        from the set {1, 2, 3, 4, 5, 6}.

        Returns:
            A `numpy.ndarray` of two numbers.
        """
        return np.random.randint(1,7,2)


    def is_game_over(self):
        """
        Checks whether the game is over or not.

        Returns:
            `True` if the game is over, otherwise `False`.
        """
        return self.board[27] == 15 or self.board[28] == -15


    # don't use
    def get_winner(self):
        """
        Returns the number of the player that won.

        Returns:
            `1` if player 1 won, `-1` if player 2 won, otherwise `0`.
        """
        # TODO: implement
        raise Exception("IMPLEMENT")


    def __verify(self):
        """
        Checks this game for obvious errors.

        Raises an exception if something goes wrong.
        """

        if sum(self.board[self.board > 0]) != 15 or sum(self.board[self.board < 0]) != -15:
            raise Exception("Too many pieces on the board.")


    def pretty_print(self, board = None):
        """
        Prints the board.

        Args:
            board: the board
        """

        if board is None:
            board = self.board

        string = str(np.array2string(board[1:13])+'\n'+
                     np.array2string(board[24:12:-1])+'\n'+
                     np.array2string(board[25:29]))
        print(string)


    def get_flipped_board(self):
        """
        Creates a flipped board without affecting the board of this game.

        Returns:
            A flipped board (ndarray).
        """

        # alias
        board = self.board

        board = board * (-1)
        main_board = board[24:0:-1]
        jail1, jail2, off1, off2 = board[26], board[25], board[28], board[27]
        main_with_zero = np.insert(main_board, 0, board[0])
        new_board = np.append(main_with_zero, np.array([jail1, jail2, off1, off2]))

        return new_board


    def flip_board(self):
        """
        "Flips" the board in-place.
        """

        self.board = self.get_flipped_board()

    def get_serial_code_for_board(self, board):
        """
        Hashes board and return a unique serial
        """
        string = ''
        for i in board:
            if i == 16:
                string += 'e'
            hex_num = str(hex(i))
            string += hex_num[-1]
        return string

    def clone(self):
        """
        Creates a clone of this backgammon game.
        """
        pass


    def copy_board(self):
        """
        Create a copy of this backgammon board.

        Returns:
            A copy of the board (ndarray) of this game in its current state.
        """
        return np.copy(self.board)


    def play(self, commentary = False, verbose = False, start_with_this_board=False):
        """
        Make player 1 and player 2 play a game of backgammon.

        When a player picks an action (s)he has

        Args:
            commentary (bool): Whether to include commentary `True`, or not `False`.

        Returns:
            `1` if player 1 won or `-1` if player 2 won.
        """

        if not type(start_with_this_board) is bool:
            self.board = start_with_this_board
            self.active_player = 1
        else:
            self.reset()
            self.active_player = 1 if random.random() > 0.5 else -1

        # player 1 starts
        #
        # TODO: roll a dice in future to determine which player stars, i.e.
        # the player which rolls higher starts, and uses those dice in his/her
        # first turn.

        # Select starting player by random

        #  1 -> player 1
        # -1 -> player 2

        # Keep making turns until one or the other player wins.
        while not self.is_game_over():

            if commentary:
                print("Lets go player: ", self.active_player)

            # Roll dice
            dice = self.roll_dice()

            # If you roll of your dice is, say 5-5, then you use 5 four times,
            # or the pair twice.
            turns = 1
            if dice[0] == dice[1]:
                turns = 2

            # np.array([1], dtype=np.int64)

            # TODO: make sure the same die is not reused.

            if verbose:
                print("====================================================================")


            # Make a move (2 moves if the same number appears on the dice)
            for i in range(turns):

                if verbose:
                    print("Dice:", dice)
                    print("")
                    print("BEFORE")
                    print(self)

                board_copy = self.copy_board()

                move = None

                if self.active_player == 1:
                    move = self.player_1.action(board_copy, dice, 1)
                elif self.active_player == -1:
                    move = self.player_2.action(board_copy, dice, 1)
                else:
                    raise Exception("This shouldn't have happened.")

                # TODO figure out which die was used

                # update the board
                if len(move) != 0:
                    for m in move:
                        self.update_board(m)

                if commentary:
                    print("move from player", self.active_player, ":")
                    #print("board:")
                    #if self.active_player == 1:
                    #    self.pretty_print()
                    #else:
                    #    self.pretty_print(self.get_flipped_board())

                if verbose:
                    print("AFTER")
                    print(self)

            # players take turns
            self.active_player = -self.active_player
            self.flip_board()

        return -self.active_player


    def update_board(self, move):
        """
        Updates the board by making the move `move`.  A `moves` moves one
        checker from some position to another.  If the checker lands on
        a blot (point occupied by one opposing checker) then the opposing
        checker is moved to the "jail".

        Args:
            move (ndarray): a pair of numbers, the first one is *from* and second is *to*.
        """

        # If we can make a move, we move.
        if len(move) > 0:

            startPip = move[0]  # from
            endPip = move[1]    # to

            # moving the dead piece if the move kills a piece
            if self.board[endPip] == -1:
                self.board[endPip] = 0
                jail = 26
                self.board[jail] = self.board[jail] - 1

            self.board[startPip] = self.board[startPip]-1
            self.board[endPip] = self.board[endPip]+1


    def __str__(self):
        """
        If you evaluate `str(x)` where `x` is an instance of `Backgammon` then
        this string (which is constructed here) is returned.

        Returns:
            A `str` representing the board of this game, and all relevant
            information.
        """
        return Backgammon.to_string(self.board)


    @staticmethod
    def to_string(board):
        """
        Returns a CLI representation of the game

        Args:
            board (ndarray): the board

        Returns:
            A CLI representation (string) of the game.
        """

        msg = ""
        height = int(np.amax([abs(x) for x in board]))

        dir_banner = "        <-- x --                                       -- o -->"

        top_banner = "   .---.-------------.-------------.-------------.-------------.---.---.---.---."

        bottom_banner = "   '-?-'-^-^-^-^-^-^-'-^-^-^-^-^-^-'-^-^-^-^-^-^-'-^-^-^-^-^-^-'-J-'-J-'-O-'-O-'"
        bottom_banner_2 = "                                                                 1   2   1   2"

        num_banner_1 = "                             1 1 1   1 1 1 1 1 1   1 2 2 2 2 2   2   2   2   2"
        num_banner_2 = "     0   1 2 3 4 5 6   7 8 9 0 1 2   3 4 5 6 7 8   9 0 1 2 3 4   5   6   7   8"

        msg += dir_banner
        msg += "\n"
        msg += top_banner
        msg += "\n"
        for i in range(height):
            submsg = ""
            j = height - i
            h = j - 1

            if j < 10:
                submsg += " " + str(j)
            else:
                submsg += str(j)

            submsg += " "
            submsg += "|"
            submsg += " "
            submsg += str_symbol(board, 0, h)
            submsg += " "
            submsg += "|"
            submsg += " "
            submsg += str_symbol(board, 1, h)
            submsg += " "
            submsg += str_symbol(board, 2, h)
            submsg += " "
            submsg += str_symbol(board, 3, h)
            submsg += " "
            submsg += str_symbol(board, 4, h)
            submsg += " "
            submsg += str_symbol(board, 5, h)
            submsg += " "
            submsg += str_symbol(board, 6, h)
            submsg += " "
            submsg += "|"
            submsg += " "
            submsg += str_symbol(board, 7, h)
            submsg += " "
            submsg += str_symbol(board, 8, h)
            submsg += " "
            submsg += str_symbol(board, 9, h)
            submsg += " "
            submsg += str_symbol(board, 10, h)
            submsg += " "
            submsg += str_symbol(board, 11, h)
            submsg += " "
            submsg += str_symbol(board, 12, h)
            submsg += " "
            submsg += "|"
            submsg += " "
            submsg += str_symbol(board, 13, h)
            submsg += " "
            submsg += str_symbol(board, 14, h)
            submsg += " "
            submsg += str_symbol(board, 15, h)
            submsg += " "
            submsg += str_symbol(board, 16, h)
            submsg += " "
            submsg += str_symbol(board, 17, h)
            submsg += " "
            submsg += str_symbol(board, 18, h)
            submsg += " "
            submsg += "|"
            submsg += " "
            submsg += str_symbol(board, 19, h)
            submsg += " "
            submsg += str_symbol(board, 20, h)
            submsg += " "
            submsg += str_symbol(board, 21, h)
            submsg += " "
            submsg += str_symbol(board, 22, h)
            submsg += " "
            submsg += str_symbol(board, 23, h)
            submsg += " "
            submsg += str_symbol(board, 24, h)
            submsg += " "
            submsg += "|"
            submsg += " "
            submsg += str_symbol(board, 25, h)
            submsg += " "
            submsg += "|"
            submsg += " "
            submsg += str_symbol(board, 26, h)
            submsg += " "
            submsg += "|"
            submsg += " "
            submsg += str_symbol(board, 27, h)
            submsg += " "
            submsg += "|"
            submsg += " "
            submsg += str_symbol(board, 28, h)
            submsg += " "
            submsg += "|"
            submsg += " "

            submsg += "\n"

            msg += submsg

        msg += bottom_banner
        msg += "\n"
        msg += bottom_banner_2
        msg += "\n"
        msg += "\n"
        msg += num_banner_1
        msg += "\n"
        msg += num_banner_2
        msg += "\n"

        return msg


    @staticmethod
    def check_if_game_is_over(board):
        """
        Checks whether the game for board `board` is over or not.

        Args:
            board (ndarray): the backgammon board

        Returns:
            `True` if the game is over, otherwise `False`.
        """
        return board[27] == 15 or board[28] == -15


    @staticmethod
    def get_updated_board(board, move):
        # updates the board
        # inputs are some board, one move and the player
        # outputs the updated board
        board_to_update = np.copy(board)

        # if the move is there
        if len(move) > 0:
            startPip = move[0]
            endPip = move[1]

            # moving the dead piece if the move kills a piece
            kill = board_to_update[endPip]==(-1)
            if kill:
                board_to_update[endPip] = 0
                jail = 26
                board_to_update[jail] = board_to_update[jail] - 1

            board_to_update[startPip] = board_to_update[startPip]-1
            board_to_update[endPip] = board_to_update[endPip]+1

        return board_to_update


    @staticmethod
    def get_player_symbol(player):
        if player == 1:
            return Backgammon.PLAYER_1_SYMBOL
        elif player == -1:
            return Backgammon.PLAYER_2_SYMBOL
        else:
            raise Exception("Shouldn't have happened!")


    @staticmethod
    def get_all_legal_moves_for_one_die(board, die):
        """
        Finds all legal moves for the backgammon board `board` and one die.

        Args:
            board (ndarray): the backgammon board
            die: the number of the die (and which player is up?)

        Returns:
            All possible moves for this die.
        """

        possible_moves = []

        if board[25] > 0:
            start_pip = 25-die
            if board[start_pip] > -2:
                possible_moves.append(np.array([25,start_pip]))
        # no dead pieces
        else:
            # adding options if player is bearing off
            if sum(board[7:25]>0) == 0:
                if (board[die] > 0):
                    possible_moves.append(np.array([die,27]))
                elif not Backgammon.check_if_game_is_over(board): # smá fix
                    # everybody's past the dice throw?
                    s = np.max(np.where(board[1:7]>0)[0]+1)
                    if s<die:
                        possible_moves.append(np.array([s,27]))

            possible_start_pips = np.where(board[0:25]>0)[0]

            # finding all other legal options
            for s in possible_start_pips:
                end_pip = s-die
                if end_pip > 0:
                    if board[end_pip] > -2:
                        possible_moves.append(np.array([s,end_pip]))

        return possible_moves


    @staticmethod
    def get_all_legal_moves_for_two_dice(board, dice):
        """
        Finds all possible moves and their corresponding after-states.

        NOTE: an after-state is simply what the board will look like after making
        the move.

        Args:
            board (ndarray): backgammon board
            dice (ndarray): the dice rolled by player (and which player is up?)

        Returns:
            A tuple of `moves` (if they exists) and their corresponding after-states `boards`.
        """
        # finds all possible moves and the possible board after-states
        # inputs are the BG-board, the dices rolled and which player is up
        # outputs the possible pair of moves (if they exists) and their after-states

        moves = []
        boards = []

        # try using the first dice, then the second dice
        possible_first_moves = Backgammon.get_all_legal_moves_for_one_die(board, dice[0])
        for m1 in possible_first_moves:
            temp_board = Backgammon.get_updated_board(board,m1)
            possible_second_moves = Backgammon.get_all_legal_moves_for_one_die(temp_board,dice[1])
            for m2 in possible_second_moves:
                moves.append(np.array([m1,m2]))
                boards.append(Backgammon.get_updated_board(temp_board,m2))

        if dice[0] != dice[1]:
            # try using the second dice, then the first one
            possible_first_moves = Backgammon.get_all_legal_moves_for_one_die(board, dice[1])
            for m1 in possible_first_moves:
                temp_board = Backgammon.get_updated_board(board,m1)
                possible_second_moves = Backgammon.get_all_legal_moves_for_one_die(temp_board,dice[0])
                for m2 in possible_second_moves:
                    moves.append(np.array([m1,m2]))
                    boards.append(Backgammon.get_updated_board(temp_board,m2))

        # if there's no pair of moves available, allow one move:
        if len(moves)==0:
            # first dice:
            possible_first_moves = Backgammon.get_all_legal_moves_for_one_die(board, dice[0])
            for m in possible_first_moves:
                moves.append(np.array([m]))
                boards.append(Backgammon.get_updated_board(temp_board,m))

            # second dice:
            possible_first_moves = Backgammon.get_all_legal_moves_for_one_die(board, dice[1])
            for m in possible_first_moves:
                moves.append(np.array([m]))
                boards.append(Backgammon.get_updated_board(temp_board,m))

        return moves, boards
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
This hasn't been implemented and maybe won't be.  Ignore for the time being.
"""

COMMANDS = [
    {
        "keyword": "",
        "manual": """Usage: python3 main.py ... """
    },
    {
        "keyword": "self-play",
        "manual": """    Play Backgammon with yourself"""
    }
]

def get_commands_object():
    return None
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Entry point of this program.

To get default (old) behavior, run `python3 main.py default`.

Usage: python3 main.py ...
"""
import os
import sys
from pathlib import Path

import numpy as np

from cli_commands import get_commands_object

from backgammon_game import Backgammon
from pub_stomper_agents.human_agent import HumanAgent
from pub_stomper_agents.dyna_2_agent import Dyna2Agent
from pub_stomper_agents.random_agent import RandomAgent
from pub_stomper_agents.nn_agent_1 import NNAgent1

from pub_stomper_agents.agent import get_agent_by_config_name
from pub_stomper_lib.utils import hash_json, load_file_as_json
from statistic import Statistic
from pub_stomper_all_vs_all import play_all_vs_all

# Set logs
verbose = True

def do_default():
    """
    Play with a neural network against random
    """
    player1 = get_agent_by_config_name('nn_dyna2', 'new')
    player2 = RandomAgent()

    player1.training = True
    player2.training = True

    stats = Statistic(player1, verbose=True)

    # play games forever
    while True:

        bg = Backgammon()
        bg.set_player_1(player1)
        bg.set_player_2(player2)
        winner = bg.play()

        player1.add_reward(winner)
        player2.add_reward(-winner)

        # Reward the neural network agent
        # player1.reward_player(winner)

        stats.add_win(winner)

def nn_vs_nn_export_better_player():
    player1 = NNAgent1(verbose = True)
    player2 = NNAgent1(load_best=True)

    stats = Statistic(player1, verbose=True)

    while True:
        bg = Backgammon()
        bg.set_player_1(player1)
        bg.set_player_2(player2)
        winner = bg.play()

        player1.add_reward(winner)
        player2.add_reward(-1 * winner)

        stats.add_win(winner)

        if stats.nn_is_better() and stats.games_played % 100 == 0:
            break

    # only way to reach this point is if the current
    # neural network is better than the BestNNAgent()
    # ... at least I think so
    # thus, we export the current as best
    print("Congratulations, you brought the network one step closer")
    print("to taking over the world (of backgammon)!!!")
    player1.export_model(filename="nn_best_model")


def self_play():
    """
    Makes a human agent play against another (or the same) human agent.
    """

    player1 = HumanAgent()
    player2 = HumanAgent()

    bg = Backgammon()
    bg.set_player_1(player1)
    bg.set_player_2(player2)
    bg.play()


def random_play():
    """
    Makes a random agent play against another random agent.
    """

    player1 = RandomAgent()
    player2 = RandomAgent()

    bg = Backgammon()
    bg.set_player_1(player1)
    bg.set_player_2(player2)
    bg.play(commentary=True, verbose=True)


def test_play():
    """
    Makes a human agent play against another (or the same) human agent.
    """

    player1 = HumanAgent()
    player2 = get_agent_by_config_name('nn_pg', 'best')

    bg = Backgammon()
    bg.set_player_1(player1)
    bg.set_player_2(player2)
    bg.play()


def main():
    """
    The main function, obviously.
    """
    commands = get_commands_object()

    # Arguments
    args = sys.argv[1:]

    # No argument provided
    if len(args) == 0:
        print("Usage: python3 " + str(sys.argv[0]) + " [COMMAND]")
        print("")
        print("Commands:")
        print("")
        print("    default")
        print("    self-play")
        print("    random-play")
        print("    test-play")
        print("    challange-best-network")
        print("    all_vs_all [competition_test.json or other]")
        print("    jsonhash <path to json>")
        # Stop execution if no argument
        return

    # svo glarb glitchar ekki
    args.append(False)
    if args[0] == "default":
        do_default()
    elif args[0] == "self-play":
        self_play()
    elif args[0] == "random-play":
        random_play()
    elif args[0] == "challange-best-network":
        nn_vs_nn_export_better_player()
    elif args[0] == "test-play":
        test_play()
    elif args[0] == "all_vs_all":
        play_all_vs_all(args[1])
    elif args[0] == "jsonhash":
        try:
            path = " ".join(args[1:])
            print(hash_json(load_file_as_json(path)))
        except:
            print("File is not JSON.")
    else:
        print("Say what?")


if __name__ == "__main__":
    main()
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
A parallel network or something...
"""
import torch
import torch.nn as nn
import itertools
from functools import reduce

input_width = 464
output_width = 10
hidden_layers = [250, 250]
dtype=torch.double
td_n = 2

learning_rate = 5e-5
node_count = 2
last_vector = node_count * output_width

def make_layers():
    layers = []

    last_width = input_width
    for layer_width in hidden_layers:
        layers.append(nn.Linear(last_width, layer_width))
        layers.append(nn.ReLU())
        last_width = layer_width
    final = nn.Linear(last_width, output_width)

    layers.append(final)
    return layers


class Node(nn.Module):
    
    def __init__(self):
        super(Node, self).__init__()
        self.model = nn.Sequential(*make_layers())

    def forward(self, board):
        return self.model(board)

    def predict(self, board):
        with torch.no_grad():
            return self.model(board)

    def run_decision(self, board):
        return self.model(board)

    def make_nodes(n):

        nodes = []
        for i in range(n):
            nodes.append(Node())
        return nodes

    def get_parameters(nodes):
        chained = []
        for node in nodes:
            itertools.chain(chained, node.parameters())
        return chained


class ParallelNetwork(nn.Module):
    filename = 'parallel_test'

    def __init__(self):
        super(ParallelNetwork, self).__init__()
        self.predictions = torch.empty((1), dtype = dtype, requires_grad=True)
        self.nodes = make_nodes(node_count)
        self.prefinal = nn.Linear(last_vector, 50)
        self.final = nn.Linear(50, 1)
        self.loss_fn = loss_fn = torch.nn.MSELoss(size_average=False)
        self.optimizer = torch.optim.SGD(itertools.chain(self.prefinal.parameters(), self.final.parameters(), get_parameters(self.nodes)), momentum=0.9, lr=learning_rate)

    def forward(self, board):
        tensor = []
        for node in self.nodes:
            tensor.append(node(board))
        node_out = torch.stack(tensor)
        node_out = node_out.view((last_vector))
        digestion = self.prefinal(node_out)
        output = self.final(digestion)
        return output

    def run_decision(self, board_features):
        vector = board_features
        prediction = self(board_features)
        self.predictions = torch.cat((self.predictions, prediction.double()))

    def predict(self, board_features):
        with torch.no_grad():
            return self(board_features)

    def get_reward(self, reward, exp_return):
        episode_length = len(self.predictions)
        y = torch.ones((episode_length), dtype=dtype) * reward


        with torch.no_grad():
            for i in range(len(self.predictions)):
                if i == len(self.predictions) - td_n:
                    break
                y[i] = self.predictions[i + td_n]

        """
        for i in range(episode_length):
            y[i] = (y[i] * i + (episode_length - (i + 1) ) * exp_return) / (episode_length - 1)
        """


        loss = (self.predictions - y).pow(2).sum() / episode_length
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()
        # print(self.predictions - torch.ones((episode_length), dtype=dtype) * torch.mean(self.predictions))

        print("Expected return")
        print(exp_return)
        print("")
        print("First state td value")
        print(y[0])
        print("Prediction of last state ('-' means guessed wrong, number is confidence, optimal = 1 > p > 0.8) ")
        print(str(float(self.predictions[episode_length - 1] * reward)))
        print("First state")
        print(str(float(self.predictions[0])))
        self.predictions = torch.empty(0, dtype = dtype, requires_grad=True)
        # kalla a predictions.sum til ad kalla bara einu sinni a
        # loss.backward()

import numpy as np
import random

from pub_stomper_policy import Policy
from pub_stomper_basic_network_for_testing import BasicNetworkForTesting
from parallel_network import ParallelNetwork

class PolicyPsuedo(Policy):

    def __init__(self, neural_net, should_update=False, verbose=False, agent_cfg=None, imported=False, pub_stomper_policy_decision_function='argmax'):
        """
        Args:
            load_best (bool): default `False`
            verbose (bool): default `False`
            export (bool): default `False`
            agent_cfg: default `None`
            archive_name: default `None`.
        """

        self.verbose = verbose
        self.net = neural_net

        self.should_update = should_update

    def argmax(self, move_ratings):
        # get max value
        max = move_ratings[0]
        max_i = 0
        for i, move in enumerate(move_ratings):
            if move > max:
                max = move
                max_i = i
        return max_i

    def evaluate(self, possible_boards):
        """
        Evaluates the possible boards given to this method as an argument and
        returns a move.

        Args:
            possible_boards: possible boards

        Returns:
            A move.
        """
        # variable to hold ratings
        move_ratings = []

        # predict win_rate of each possible after-state (possible_boards)
        for board in possible_boards:
            value_of_board = self.net.predict(self.get_feature_vector(board))
            move_ratings.append(value_of_board)

        move = 0
        # move = best_move if random.random() > self.epsilon else random.rand_int(len(possible_boards - 1)) # uncomment for e_greedy
        self.net.run_decision(self.get_feature_vector(possible_boards[move]))

        return move

    def save(self, save_as_best=False):
        return self.net.save(save_as_best=save_as_best)

    def load(self, filename):
        self.net.load(filename)

    def get_filename(self):
        """
        Returns the file name for this neural network attached to this instance.

        Returns:
            The file name of the neural network.
        """
        return self.net.filename

    def add_reward(self, reward):
        if self.should_update:
            self.net.give_reward_to_nn(reward)
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
A class, or interface, for pub_stomper_agents. 
"""

class AgentInterface():
    """
    A standardized interface for pub_stomper_agents.
    """

    def __init__(self, training = False):
        """
        Instantiates an standardized agent interface.

        Args:
            training (bool): whether this agent is training, default `False`
        """

        self.training = training


    def action(self, board, dice, player):
        """
        This method returns a list of two least, and ea contain two numbers, 
        e.g.

            [ [18, 16], [16, 10] ]

        We move a checker from 18 to 16 and a checker from 16 to 10.

        Args:
            board (ndarray): backgammon board
            dice (ndarray): a pair of dice
            player: the number for the player on the board who's turn it is.

        Returns:
            A move `move`.
        """
        raise Exception("Not implemented!")


    def add_action(self, action):
        """
        Adds action `action`.

        Args:
            action: the action.
        """
        raise Exception("Not implemented!")


    def add_reward(self, reward):
        """
        Adds reward `reward`.

        Args:
            reward (number): the reward
        """
        raise Exception("Not implemented!")
    

    def add_state(self, state):
        """
        Adds state `state`.

        Args:
            state: the state
        """
        raise Exception("Not implemented!")


    def load(self, filepath = None):
        """
        Loads agent from disk.

        NOTE: Refrain from using `filepath`.

        Returns:
            Path to where the file is saved.
        """
        raise Exception("Not implemented!")
    

    def save(self, filepath = None):
        """
        Saves agent to disk.

        NOTE: Refrain from using `filepath`.

        Returns:
            Path to where the file is saved.
        """
        raise Exception("Not implemented!")


#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
A neural network agent.
"""
import numpy as np

from pub_stomper_agents.agent_interface import AgentInterface
from backgammon_game import Backgammon

from pub_stomper_policy_neural_network import PolicyNeuralNetwork


class PsuedoAgent(AgentInterface):

    training = True

    def __init__(self, psuedo_policy):
        """
        Creates a neural network agent.

        To load the best NNAgent1 simply set load_best=True

        Args:
            load_best: default `False`
            verbose: default `False`
        """
        AgentInterface.__init__(self)
        self.pub_stomper = psuedo_policy



    def action(self, board, dice, player):
        """
        Args:
            board (ndarray): backgammon board
            dice (ndarray): a pair of dice
            player: the number for the player on the board who's turn it is.

        Returns:
            A move `move`.
        """

        move = []
        possible_moves, possible_boards = Backgammon.get_all_legal_moves_for_two_dice(board, dice)

        if len(possible_moves) != 0:
            move = self.pub_stomper_policy(possible_moves, possible_boards, dice)

        return move

    def add_action(self, action):
        pass

    def add_reward(self, reward):
        """
        Adds reward `reward` to this neural network agent.

        NOTE: if you add a reward to the neural network it will immediately
        train.
        """

        # Hence, we only add rewards when we're training..
        if self.training:
            self.pub_stomper.add_reward(reward)

    def add_state(self, state):
        pass

    def load(self, filename):
        self.pub_stomper.load(filename)

    def save(self, save_as_best=False):
        return self.pub_stomper.save(save_as_best)

    def get_filename(self):
        # obsolete
        return self.pub_stomper.get_filename()

    def pub_stomper_policy(self, possible_moves, possible_boards, dice):

        best_move = self.pub_stomper.evaluate(possible_boards)
        move = possible_moves[best_move]

        # gamli kodinn fyrir random
        # move = possible_moves[np.random.randint(len(possible_moves))]
        return move
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
A neural network agent.
"""
import numpy as np

from pub_stomper_agents.agent_interface import AgentInterface
from backgammon_game import Backgammon

from pub_stomper_policy_neural_network import PolicyNeuralNetwork
from pub_stomper_policy_pg_network import PolicyPGNetwork


class NNAgent1(AgentInterface):

    training = True

    def __init__(self, verbose=False, agent_cfg=None, imported=False):
        """
        Creates a neural network agent.

        To load the best NNAgent1 simply set load_best=True

        Args:
            load_best: default `False`
            verbose: default `False`
        """
        AgentInterface.__init__(self)
        if agent_cfg['cfg']['use_policy_gradient']:
            self.pub_stomper = PolicyPGNetwork(verbose=verbose, agent_cfg=agent_cfg, imported=imported)
        else:
            self.pub_stomper = PolicyNeuralNetwork(verbose=verbose, agent_cfg=agent_cfg, imported=imported)



    def action(self, board, dice, player):
        """
        Args:
            board (ndarray): backgammon board
            dice (ndarray): a pair of dice
            player: the number for the player on the board who's turn it is.

        Returns:
            A move `move`.
        """

        move = []
        possible_moves, possible_boards = Backgammon.get_all_legal_moves_for_two_dice(board, dice)

        if len(possible_moves) != 0:
            move = self.pub_stomper_policy(possible_moves, possible_boards, dice)

        return move

    def add_action(self, action):
        pass

    def add_reward(self, reward):
        """
        Adds reward `reward` to this neural network agent.

        NOTE: if you add a reward to the neural network it will immediately
        train.
        """

        # Hence, we only add rewards when we're training..
        if self.training:
            self.pub_stomper.add_reward(reward)

    def add_state(self, state):
        pass

    def load(self, filename):
        self.pub_stomper.load(filename)

    def save(self, save_as_best=False):
        return self.pub_stomper.save(save_as_best)

    def get_filename(self):
        # obsolete
        return self.pub_stomper.get_filename()

    def pub_stomper_policy(self, possible_moves, possible_boards, dice):

        best_move = self.pub_stomper.evaluate(possible_boards)
        move = possible_moves[best_move]

        # gamli kodinn fyrir random
        # move = possible_moves[np.random.randint(len(possible_moves))]
        return move
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
"""
import numpy as np

from pub_stomper_agents.agent_interface import AgentInterface
from backgammon_game import Backgammon


class RandomAgent(AgentInterface):

    def __init__(self):
        pass

    def action(self, board, dice, player):
        """
        Args:
            board (ndarray): backgammon board
            dice (ndarray): a pair of dice
            player: the number for the player on the board who's turn it is.

        Returns:
            A move `move`.
        """

        # check out the legal moves available for dice throw
        move = []
        possible_moves, _ = Backgammon.get_all_legal_moves_for_two_dice(board, dice)

        if len(possible_moves) == 0:
            return []
        else:
            move = possible_moves[np.random.randint(len(possible_moves))]
        
        return move
    
    def add_reward(self, reward):
        pass

    def save(self):
        pass
    
    def load(self):
        pass
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
"""
import re

import numpy as np

from pub_stomper_agents.agent_interface import AgentInterface
from backgammon_game import Backgammon


def parse_input(s):
    """
    Parses the input `s` into `None` or a move.

    Args:
        s (str): a string which looks something like "3 21"
    
    Returns:
        A move or `None`.
    """
    s = s.strip()
    if len(s) == 0:
        return []
    else:
        try:
            input_pair = re.compile("\\s+").split(s)
            pos_from = int(input_pair[0])
            pos_to = int(input_pair[1])
            move = np.array([pos_from, pos_to], dtype=np.int64)
            return move
        except:
            return None


class HumanAgent(AgentInterface):

    def __init__(self):
        AgentInterface.__init__(self)

    def action(self, board, dice, player):
        """
        Args:
            board (ndarray): backgammon board
            dice (ndarray): a pair of dice
            player: the number for the player on the board who's turn it is.

        Returns:
            A move `move`.
        """

        all_legal_moves = Backgammon.get_all_legal_moves_for_two_dice(board, dice)[0]

        # Runs this until a legal move is made.
        while True:

            print(Backgammon.to_string(board))
            print("")
            print("   You: " + str(Backgammon.get_player_symbol(player)))
            print("   Dice: " + str(dice))
            print("")
            print("    Press (enter) to pass if no moves are possible.")
            print("    Syntax: POSITION_FROM POSITION_TO")

            if len(all_legal_moves) == 0:
                # No possible moves
                print("No possible moves.  Press (enter) to continue.")
                input("Input: ")
                return []
            else:
                # Some moves possible
                move_1 = parse_input(input("Input: "))

                valid_move_1 = False

                future_legal_moves = []

                for moves in all_legal_moves:
                    if len(moves) > 0:
                        first_move = moves[0]
                        if len(first_move) == 2:
                            if first_move[0] == move_1[0] and first_move[1] == move_1[1]:
                                valid_move_1 = True
                                future_legal_moves += [moves[1]]
                
                if valid_move_1:
                    # Check if future moves are possible
                    if len(future_legal_moves) == 0:
                        return [move_1]
                    else:
                        move_2 = parse_input(input("Input: "))

                        for second_move in future_legal_moves:
                            if second_move[0] == move_2[0] and second_move[1] == move_2[1]:
                                return [move_1, move_2]
                        
                        print("Invalid second move")
                else:
                    print("Invalid move")

    def add_action(self, action):
        pass
    
    def add_reward(self, reward):
        pass

    def add_state(self, state):
        pass
    
    def load(self, filepath = None):
        pass
    
    def save(self, filepath = None):
        pass

#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
A neural network agent.
"""
import numpy as np

from pub_stomper_agents.agent_interface import AgentInterface
from backgammon_game import Backgammon

from pub_stomper_policy_dyna_2 import PolicyDyna2


class Dyna2Agent(AgentInterface):

    training = True

    def __init__(self, verbose=False, agent_cfg=None, imported=False):
        self.dyna2 = PolicyDyna2(verbose=verbose, agent_cfg=agent_cfg, imported=imported)
        """
        Creates a neural network agent.

        To load the best NNAgent1 simply set load_best=True

        Args:
            load_best: default `False`
            verbose: default `False`
        """
        AgentInterface.__init__(self)

    def action(self, board, dice, player):
        """
        Args:
            board (ndarray): backgammon board
            dice (ndarray): a pair of dice
            player: the number for the player on the board who's turn it is.

        Returns:
            A move `move`.
        """

        move = []
        possible_moves, possible_boards = Backgammon.get_all_legal_moves_for_two_dice(board, dice)

        if len(possible_moves) != 0:
            move = self.pub_stomper_policy(possible_moves, possible_boards, dice, board)

        return move


    def add_action(self, action):
        pass

    def add_reward(self, reward):
        """
        Adds reward `reward` to this neural network agent.

        NOTE: if you add a reward to the neural network it will immediately
        train.
        """
        # Hence, we only add rewards when we're training..
        self.dyna2.add_reward(reward)

    def add_state(self, state):
        raise Exception('Add')
        pass

    def load(self, filename):
        self.pub_stomper.load(filename)

    def save(self, save_as_best=False):
        return self.pub_stomper.save(save_as_best)

    def get_filename(self):
        # obsolete
        return self.pub_stomper.get_filename()

    def pub_stomper_policy(self, possible_moves, possible_boards, dice, board_copy):
        best_move = self.dyna2.evaluate(possible_boards, board_copy)
        move = possible_moves[best_move]

        # gamli kodinn fyrir random
        # move = possible_moves[np.random.randint(len(possible_moves))]
        return move
"""
Brain naming convention
{agent config. type}-{agent config. name}-{timestamp}[-...]
"""

from pub_stomper_agents.random_agent import RandomAgent
from pub_stomper_agents.human_agent import HumanAgent
from pub_stomper_agents.nn_agent_1 import NNAgent1
from pub_stomper_agents.dyna_2_agent import Dyna2Agent

from pathlib import Path
from pub_stomper_lib.utils import hash_string, does_file_exist, hash_json, load_file_as_string, load_file_as_json, print_json
import os

agent_cfgs = {}

def load_agent_cfgs(dirname = "pub_stomper_configs"):
    """
    Load all agent pub_stomper_configs
    DONT IMPORT
    """
    agent_cfg_filenames = list(filter(lambda name: name[0:5] == 'agent' and name[-4:] == 'json', os.listdir(dirname)))
    for agent_cfg_filename in agent_cfg_filenames:
        filepath = str(Path(dirname, agent_cfg_filename))
        agent_cfg = load_file_as_json(filepath)
        name = agent_cfg['name']
        if name not in agent_cfgs:
            agent_cfgs[name] = agent_cfg
        else:
            raise Exception("At least two agent pub_stomper_configs. share the same name: " + str(name))

# TODO: implement reload
# Yolo
def get_agent_config_by_config_name(config_name):
    return agent_cfgs[config_name]

def get_agent_by_config_name(config_name, brain_type):
    """
    Loads in agent by agent configuartion name.
    """
    # Agent configartion JSON.
    agent_cfg = get_agent_config_by_config_name(config_name)
    agent_cfg_name = agent_cfg['name']
    agent_cfg_type = agent_cfg['type']

    # TODO: implement load brain
    # Brain name
    agent = None
    if agent_cfg_type == "random":
        agent = RandomAgent()
    elif agent_cfg_type == "human":
        agent = HumanAgent()
    elif agent_cfg_type == "nn1":
        if brain_type == "new":
            agent = NNAgent1(agent_cfg=agent_cfg)
        elif brain_type == "best":
            agent = NNAgent1(agent_cfg=agent_cfg, imported=True)
        else:
            raise Exception("Something is not right")
    elif agent_cfg_type == 'best_nn1':
        agent = NNAgent1(agent_cfg = agent_cfg, imported=True)
    elif agent_cfg_type == 'dyna2':
        print('welcome to bug territory, enjoy your stay', brain_type)
        if brain_type == "new":
            agent = Dyna2Agent(agent_cfg = agent_cfg)
        else:
            agent = Dyna2Agent(agent_cfg = agent_cfg, imported=True)

    else:
        raise Exception('Unknown type of agent: ' + str(agent_cfg_type))

    return agent

load_agent_cfgs()


# do_glarb with no manifest.json

import os
import numpy as np
from pathlib import Path
from pub_stomper_lib.utils import load_file_as_json
from backgammon_game import Backgammon
from pub_stomper_agents.agent import get_agent_config_by_config_name, get_agent_by_config_name

from trueskill import Rating, quality_1vs1, rate_1vs1

def update_rating(rating1, rating2, result):
    """
    Updates rating for player 1 (`rating1`) and rating for player 2 (`rating2`).

    Args:
        rating1: rating for player 1
        rating2: rating for player 2
        result: +1 if player 1 won, 0 if there was a tie, and -1 is player 2 won.

    Returns:
        Updated (rating1', rating2')
    """
    new_rating1 = None
    new_rating2 = None

    # (result == 1) means player1 won else player2 won
    if   result == 1:  new_rating1, new_rating2 = rate_1vs1(rating1, rating2)
    elif result == -1: new_rating2, new_rating1 = rate_1vs1(rating2, rating1)
    else:
        raise Exception("This shouldn't have happened!", result)

    return (new_rating1, new_rating2)

def rating_to_string(rating):
    fmt_s = '{0:.6f}'
    mu = rating.mu
    sigma = rating.sigma
    return "µ = " + str.format(fmt_s, mu) + ", σ = " + str.format(fmt_s, sigma)

def random_pair_not_self(array):
    """
    Returns:
        2 distinct elements from array
    """
    n = len(array)
    if n <= 1:
        raise Exception("Not enough players, if you're using 2, use ")
    while True:
        index_player1, index_player2 = np.random.randint(0, n), np.random.randint(0, n)
        if not index_player1 == index_player2:
            return array[index_player1], array[index_player2]


def update_wins_and_losses(result, competitor1, competitor2):
    competitor1['played_games'] += 1
    competitor2['played_games'] += 1
    if result > 0:
        competitor1['wins'] += 1
        competitor2['losses'] += 1
    else:
        competitor1['losses'] += 1
        competitor2['wins'] += 1

def print_competitors(competitors, iteration):
    print("")
    print("")
    print("State at game number: " + str(iteration))
    print("")
    print("Rating of each player")
    print("")
    # sort players highest skill to lowest
    competitors.sort(key=lambda competitor: competitor['rating'], reverse=True)

    for i, competitor in enumerate(competitors):
        rating = competitor['rating']
        name = competitor['cfg']['name']
        print("Player " + str(i + 1) + " ("  + name + "): ")
        print("    Brain type: ", competitor['brain'])
        print("    TrueSkill: " + rating_to_string(rating))
        print("    Played games: " + str(competitor['played_games']))
        print("    Wins/losses: " + str(competitor['wins']) + " / " + str(competitor['losses']))
        _wlr = float('inf') if competitor['losses'] == 0 else competitor['wins'] / competitor['losses']
        print("    Win/Loss Ratio: " + str(_wlr))



def save_competitors(competitors):
    # TODO: Gera thetta thannig ad thad save-ar alltaf besta version
    print("Saving...")
    competitor_names_already_saved = ['nn_best']
    best_network_is_playing = False
    # Save all to their corresponding place in './pub_stomper_repository'
    for competitor in competitors:
        name_of_competitor = competitor['cfg']['name']
        # BETA: Veit ekki hvort thetta virkar enntha
        # Kannski overwrite-ar thetta besta ef besta er ekki a stadnum
        if name_of_competitor == 'nn_best':
            best_network_is_playing = True
        # Check if we already saved a competitor with higher rating
        already_saved = False
        for saved_competitor_name in competitor_names_already_saved:
            if name_of_competitor == saved_competitor_name:
                already_saved = True
        # We haven't save this one then
        if already_saved:
            continue
        competitor_names_already_saved.append(name_of_competitor)
        competitor['agent'].save()

    # if the best competitor is of type nn1 we export it as best
    if competitors[0]['cfg']['type'] == 'nn1' and best_network_is_playing:
        print('Best network was: ', competitors[0]['cfg']['name'])
        competitors[0]['agent'].save(save_as_best=True)

def train(competitors):
    # Train
    print("Training...")
    iteration = 0
    while True:
        iteration += 1
        competitor1, competitor2 = random_pair_not_self(competitors)

        player1 = competitor1['agent']
        player2 = competitor2['agent']

        player1.training = True
        player2.training = True

        bg = Backgammon()
        bg.set_player_1(player1)
        bg.set_player_2(player2)

        # 1 if player 1 won, -1 if player 2 won
        result = bg.play()

        player1.add_reward(result)
        player2.add_reward(-result)
        update_wins_and_losses(result, competitor1, competitor2)

        # Rate performance
        competitor1['rating'], competitor2['rating'] = update_rating(competitor1['rating'], competitor2['rating'], result)

        if iteration % 10 == 0:
            print_competitors(competitors, iteration)

        if iteration % (100 * len(competitors)) == 0:
            save_competitors(competitors)


def make_competitor(competitor_info):
    agent_config_name = competitor_info['cfg']
    print(competitor_info)
    brain_type = competitor_info['brain']
    agent_cfg = get_agent_config_by_config_name(agent_config_name)
    agent = get_agent_by_config_name(agent_config_name, brain_type)
    return {
        "brain": brain_type,
        "cfg": agent_cfg,
        "agent": agent,
        "rating": Rating(25, 25/3),
        "played_games": 0,
        "losses": 0,
        "wins": 0,
        "agent_config_name": agent_config_name,
    }


def play_all_vs_all(competition_cfg_file):
    if not competition_cfg_file: competition_cfg_file = 'competition_test'
    path = "pub_stomper_configs/" + competition_cfg_file + '.json'

    #
    competition_setup = load_file_as_json(path)

    # Get competitors information.
    competitors = competition_setup["competitors"]

    def make_params(competitor_info):
        return [agent_config_name, agent_cfg, agent]

    competitors = list(map(lambda comp_info: make_competitor(comp_info), competitors))
    train(competitors)
    print_competitors(competitors, iteration)
    print("Exiting...")
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
This *IS* the neural network under consideration.
"""
import torch
import torch.nn as nn
import torch.nn.functional as Function
import torch.optim as Optimizer
from torch.autograd import Variable
import numpy as np
import datetime
from functools import reduce
from pathlib import Path
import copy
import os

from pub_stomper_lib.utils import load_file_as_json, get_random_string, rename_file_to_content_addressable, unarchive_archive, archive_files


dtype = torch.double
device = torch.device("cpu")
device = torch.device("cuda:0") # Uncomment this to run on GPU

default_filename = "_".join(str(datetime.datetime.now()).split(" "))

default_agent_cfg = copy.deepcopy(load_file_as_json('pub_stomper_configs/agent_nn_default.json'))

class BasicNetworkForTesting():
    """
    Creates a basic neural network for testing.
    """

    # make this one output [nn.Linear, nn.Linear...] or whatever layers you would like, then the rest is automatic
    def make_layers(self, agent_cfg):
        layers_widths = []
        layers_widths += [ agent_cfg['cfg']['neural_network']['input_layer']   ]
        layers_widths +=   agent_cfg['cfg']['neural_network']['hidden_layers']
        layers_widths += [ agent_cfg['cfg']['neural_network']['output_layer']  ]
        # Total number of layers
        n = len(layers_widths)
        layers = []
        for i in range(n - 1):
            layer_width_left  = layers_widths[i]
            layer_width_right = layers_widths[i + 1]
            linear_module = nn.Linear(layer_width_left, layer_width_right)
            # layers.append(nn.ReLU()) # uncomment for ReLU
            # layers.append(nn.Dropout(p=0.025)) # uncomment for drop-out
            layers += [linear_module]
            # layers.append(nn.ReLU()) # uncomment for ReLU
        try:
            if self.cfg_neural_network['sigmoid']:
                layers += [torch.nn.Sigmoid()]
        except KeyError:
            do_nothing = 0
        return layers

    def make_filename_from_string(self, filename_root_string):
        # sets class-wide filename for exporting to files
        self.filename_model = './pub_stomper_repository/' + filename_root_string + "_model.pt"
        self.filename_optimizer = './pub_stomper_repository/' + filename_root_string + "_optim.pt"

    def parse_json(self, agent_cfg):
        self.cfg_sgd = agent_cfg['cfg']['sgd']
        self.cfg_neural_network = agent_cfg['cfg']['neural_network']
        self.name = agent_cfg['name']
        self.filename = agent_cfg['cfg']['filename']

    def __init__(self, verbose=False, filename_of_network_to_bo_loaded = False, agent_cfg = None, imported=False, use_sigmoid=False):
        """
        Args:
            filename_of_network_to_bo_loaded: default `False`
            export: default `False` 
            verbose: default `False`
            agent_cfg: default `False`
            archive_name: default `None`
        """
        self.verbose = verbose
        self.use_sigmoid = use_sigmoid
        agent_cfg = agent_cfg if agent_cfg else default_agent_cfg
        self.parse_json(agent_cfg)

        # set up filenames for exporting
        self.make_filename_from_string(self.filename)

        self.model = nn.Sequential(*self.make_layers(agent_cfg))
        self.optimizer = torch.optim.SGD(self.model.parameters(), momentum = self.cfg_sgd['momentum'], lr = self.cfg_sgd['learning_rate'])

        # If import if the config tells us to import it
        if imported:
            self.load()
            return

        # make layers in neural network and make the network sequential
        # (i.e) input -> layer_1 -> ... -> layer_n -> output  for layers in 'make_layers()'
        # loss function
        self.loss_fn = loss_fn = torch.nn.MSELoss(size_average=False)
        # optimizer

    def save_clone(self, name):
        torch.save(self.model, 'clone_model_' + name)
        torch.save(self.optimizer.state_dict(), 'clone_optim_' + name)

    def load_clone(self, name):
        self.model = torch.load('clone_model_' + name)
        self.optimizer = torch.optim.SGD(self.model.parameters(), momentum = self.cfg_sgd['momentum'], lr = self.cfg_sgd['learning_rate'])
        self.optimizer.load_state_dict(torch.load('clone_optim_' + name))

    def save(self, save_as_best=False):
        """
        Exports everything related to the instantiation of this class to a
        ZIP file.
        Args:
            directory: directory where to place archive

        Returns:
            The path to the ZIP file.
        """
        if save_as_best:
            self.make_filename_from_string('nn_best')

        print("Saving: " + self.filename_model + ' and ' + self.filename_optimizer)

        # Save model
        torch.save(self.model, self.filename_model)
        # filename_model = rename_file_to_content_addressable(filename_model, ignore_extension=True, extension="_model.pt")

        # Save optimizer
        torch.save(self.optimizer.state_dict(), self.filename_optimizer)
        # filename_optimizer = rename_file_to_content_addressable(filename_optimizer, ignore_extension=True, extension="_optim.pt")

        self.make_filename_from_string(self.filename)

        return self.filename_model, self.filename_optimizer


    def load(self):
        print("Loading: " + self.filename_model + ' and ' + self.filename_optimizer)
        # CHECK IF FILE EXISTS
        if not os.path.isfile(self.filename_model) and not os.path.isfile(self.filename_optimizer):
            raise Exception('Did not find model or optimizer, export the model at least once first: \n',
                            '   Model name: ' + self.filename_model,
                            '   Edit ./pub_stomper_configs/agent_' + self.name + '.json so you have "imported: false" and "exported: true"')

        self.model = torch.load(self.filename_model)
        self.optimizer = torch.optim.SGD(self.model.parameters(), momentum = self.cfg_sgd['momentum'], lr = self.cfg_sgd['learning_rate'])
        self.optimizer.load_state_dict(torch.load(self.filename_optimizer))


    # initialize prediction storage
    predictions = torch.empty((1), dtype = dtype, requires_grad=True)

    # run a feature vector through the model accumulating greadient
    def run_decision(self, board_features, save_predictions=True):
        prediction = self.model(board_features)
        if save_predictions:
            self.predictions = torch.cat((self.predictions, prediction.double()))
        return prediction

    # run a feature vector through the model without accumulating gradient
    def predict(self, board_features):
        """
        This method behaves like the value function.

        Note:
        'with torch.no_grad()' allows us to run things through the network without
        calculating gradients. Although it doesn't affect the learning-process of the
        network it does save a lot of computing power.

        Args:
            board_features (ndarray or list): the feature vector for the board under consideration.

        Returns:
            The value of the board represented by the feature vector
        """
        with torch.no_grad():
            # This inputs the feature vector (features) into the neural
            # network, denoted `self.model` and outputs a number (the value of
            # the board).
            return self.model(board_features)


    def manually_reset_grad(self):
        self.optimizer.zero_grad()
    # for use in pub_stomper_policy gradient
    def manually_update_weights_of_network(self):
        self.optimizer.step()
        self.optimizer.zero_grad()

    # Initialize reward storage and statistical variables
    rewards = []
    counter = 0
    last_500_wins = np.zeros(500)
    # Function run on the end of each game.
    def give_reward_to_nn(self, reward):
        """

        TODO: this is problematic because we might not want to train the network yet,
        i.e. maybe we want to accumulate rewards and games then train

        We at this point have accumulated predictions of the network in self.predictions
        Here we decide what values we should move towards. We shall name that
        vector 'y'

        NOTE: This method does all the learning.


        Args:
            reward (number): the reward (a scalar)
            verbose (boolean): print out log for details
        """

        episode_length = len(self.predictions)
        y = torch.ones((episode_length), dtype=dtype, requires_grad=False) * reward

        # TD valued reward
        with torch.no_grad():
            for i in range(len(self.predictions)):
                if i == len(self.predictions) - self.cfg_neural_network['temporal_delay']:
                    break
                y[i] = self.predictions[i + self.cfg_neural_network['temporal_delay']]

        self.rewards.append(y)

        # Sum of squared error as loss
        loss = (self.predictions - y).pow(2).sum()
        # Zero all accumulated gradients
        self.optimizer.zero_grad()
        # Recalculate gradients based on 'loss' (i.e. what it takes for loss -> 0)
        loss.backward()
        # Use optimizer to calculate new weights
        self.optimizer.step()

        # Export model each 100 episodes
        self.counter += 1

        if self.verbose:
            # Log out statistics of current game
            self.last_500_wins[self.counter % 500] = reward
            exp_return = np.sum(self.last_500_wins) / 500 # this is from -1 to 1
            print(self.counter)
            print("")
            print("Expected return")
            print(exp_return)
            print("First state td value")
            print(y[0])
            print("Prediction of last state ('-' means guessed wrong, number is confidence, optimal = 1 > p > 0.8) ")
            print(str(float(self.predictions[episode_length - 1] * reward)))
            print("First state")
            print(str(float(self.predictions[0])))

        # reset empty predictions
        self.predictions = torch.empty(0, dtype = dtype, requires_grad=True)
        # kalla a predictions.sum til ad kalla bara einu sinni a
        # loss.backward()
import json
from pathlib import Path

import os
import os.path
import copy

import hashlib
import random

import zipfile
import time

import json_stable_stringify_python as json_stable


def does_file_exist(filepath):
    return os.path.isfile(filepath)


def load_file_as_strings(filepath):
    f = open(filepath, 'r')
    lines = f.readlines()
    f.close()
    return lines


def save_strings_to_file(filepath, strings, overwrite=False):
    if not overwrite:
        if does_file_exist:
            print("Warning: " + str(filepath) + " already exists!")
            return
    f = open(filepath, 'w')
    f.writelines(strings)
    f.close()


def rename_file_to_content_addressable(filename, alg="sha1", ignore_extension = False, extension = ""):
    """
    Renames the file `addressable` so that it becomes content adddressable
    by using hashing algorithm `alg`.  I.e. the name of the file will be it's
    hash digest in hexadecimal.

    Args:
        filename: ...
        alg: ..
        ignore_extension: 
        extension: 

    Returns:
        Returns a string of the new filename
    """

    hash_digest = hash_file(filename, alg)

    base = os.path.basename(filename)

    parts = list(os.path.splitext(base))
    parts[0] = hash_digest

    part_dir = os.path.dirname(filename)


    old_filename = filename

    new_filename = None

    if ignore_extension:
        new_filename = os.path.join(part_dir, parts[0])
    else:
        new_filename = os.path.join(part_dir, ''.join(parts))

    new_filename += extension

    os.rename(old_filename, new_filename)

    return new_filename


def load_file_as_string(filepath):
    f = open(filepath, 'r')
    text = f.read()
    f.close()
    return text


def save_string_to_file(filepath, string, overwrite=False):
    if not overwrite:
        if does_file_exist:
            print("Warning: " + str(filepath) + " already exists!")
            return
    f = open(filepath, 'w')
    f.write(string)
    f.close()


def load_file_as_json(filepath):
    json_dump = load_file_as_string(filepath)
    json_object = json.loads(json_dump)
    return json_object


def save_json_to_file(filepath, json_object, overwrite=False):
    """
    
    """
    if not overwrite:
        if does_file_exist:
            print("Warning: " + str(filepath) + " already exists!")
            return
    json_dump = json.dumps(json_object)
    save_string_to_file(filepath, json_dump, overwrite)


def merge_dict(from_dict, to_dict, deep_copy=False):
    """
    Merges dictionary `from_dict` into dictionary `to_dict` such that properties
    from `from_dict` overwrite properties from `to_dict`.

    NOTE: this modifies the dictionary `to_dict`.

    Args:
        from_dict: dictionary
        to_dict: dictionary
        deep_copy: deep copies from `from_dict`.  Default `False`.
    """
    # Apply "Robustness principle".
    if isinstance(from_dict, dict) and isinstance(from_dict, dict):
        # NOTE: do not put the if statement in the for body, as that is
        # much slower.
        if deep_copy:
            for key in from_dict:
                to_dict[key] = copy.deepcopy(from_dict[key])
        else:
            for key in from_dict:
                to_dict[key] = from_dict[key]


def merge_dict_sk(from_dict, to_dict, exclude_none=False, deep_copy=False):
    """
    Merges those properties from dictionary `from_dict` into dictionary `to_dict`
    whos keys exist in both dictionaries.

    NOTE: this modifies the dictionary `to_dict`.
    NOTE: merge dictionary `from_dict` into `to_dict` where they share keys (sk).

    Args:
        from_dict: dictionary
        to_dict: dictionary
        exclude_none: 
        deep_copy: deep copies from `from_dict`.  Default `False`.
    """
    # Apply "Robustness principle".
    if isinstance(from_dict, dict) and isinstance(from_dict, dict):
        # NOTE: do not put the if statement in the for body, as that is
        # much slower.
        if deep_copy:
            for key in from_dict:
                if key in to_dict:
                    v = from_dict[key]
                    if not(exclude_none and v is None):
                        to_dict[key] = copy.deepcopy(v)
                    
        else:
            for key in from_dict:
                if key in to_dict:
                    v = from_dict[key]
                    if not(exclude_none and v is None):
                        to_dict[key] = v


def get_merged_dict(from_dict, to_dict):
    """
    Creates a merged dictionary from dictionaries `from_dict` and `to_dict` 
    such that properties from `from_dict` overwrite properties from `to_dict`.

    Args:
        from_dict: dictionary
        to_dict: dictionary

    Returns:
        A merged dictionary.
    """
    merged_dict = { **to_dict, **from_dict }
    return merged_dict


def hash_string(string, alg="sha1"):
    """
    Hashes string `string` with algorithm `alg` and returns the digest

    Args:
        string: the string to hash
        alg: the hashing algorith, default `"sha1"`.

    Returns:
        The digest (string) of the string.
    """

    if alg == "sha1":
        hash_object = hashlib.sha1(string.encode())
        hex_digest = hash_object.hexdigest()
        return hex_digest
    
    raise Exception("Algorithm not supported: " + str(alg))


def hash_json(obj, alg="sha1"):
    string = json_stable.stringify(obj)
    return hash_string(string, alg)



def archive_files(archive_filename, filenames, cleanup = False):
    """
    Archives files `filenames` into ZIP file `archive_filename`.  If `cleanup`
    is `True` then the original files are removed, and only the archive 
    remains.

    Args:
        archive_filename: name of archive
        filenames: file names of files to archive
        cleanup (bool): whether to remove the files after archiving, keeping only
                        the archive.  Default `False`.
    
    Returns:
        name of archive
    """

    # Before zip-ing check if filenames exist and archive_filename does not
    # exist

    ok = True

    if does_file_exist(archive_filename):
        ok = False
        raise Exception("Archive filename already exists: " + str(archive_filename))
    
    for filename in filenames:
        if not does_file_exist(filename):
            ok = False
            raise Exception("Filename doesn't exist: " + str(filename))

    if ok:
        zip_file = zipfile.ZipFile(archive_filename, 'w')

        for filename in filenames:
            zip_file.write(filename)

        zip_file.close()

        if cleanup:
            for filename in filenames:
                os.remove(filename)

        return archive_filename
    
    return None


def print_json(json_object):
    string = json.dumps(json_object, sort_keys=True, indent=2, separators=(',', ':'))
    print(string)


def unarchive_archive(archive_filename, cleanup = False):
    """
    Unarchives archive `archive_filename` into the same directory that the
    archive is in.  If `cleanup` is `True` then the archive is removed after
    unarchiving.

    Args:
        archive_filename (str): archive
        cleanup (bool): whether to remove archive after unarchiving.  Default `False`.

    Returns:
        Returns filenames.
    """

    ok = True

    if not does_file_exist(archive_filename):
        ok = False
        raise Exception("Archive filename doesn't exists: " + str(archive_filename))

    filenames = None

    if ok:
        dirname = os.path.dirname(archive_filename)
        zip_file = zipfile.ZipFile(archive_filename, 'r')
        filenames = zip_file.namelist()
        zip_file.extractall('.')
        zip_file.close()

        for filename in filenames:
            assert does_file_exist(filename), "Extracted file doesn't exist: " + str(filename)

        if cleanup:
            os.remove(archive_filename)
        return filenames
    
    return None


def hash_file(filename, alg="sha1"):
    """
    Hash file `filename` and with algorithm `alg` and returns the digest.

    Args:
        filename: the file name of the file to hash
        alg: the hashing algorithm, default `"sha1"`.

    Returns:
        The digest (string) of the file.
    """

    hasher = None

    if alg == "sha1":
        hasher = hashlib.sha1()
    else:
        raise Exception("Algorithm not supported: " + str(alg))
    
    with open(filename, 'rb') as f:
        buf = f.read()
        hasher.update(buf)
    
    hex_digest = hasher.hexdigest()

    return hex_digest


def timestamp():
    """
    Returns number of milliseconds since January 1, 1970.

    Returns:
        integer
    """
    return int(round(time.time() * 1000))


def get_random_string(n = 10, alphabet = "0123456789abcdefghijklmnopqrstuvwxyz"):
    """
    Returns a random string.

    Args:
        n (int): length of string
        alphabet (str): the alphabet to pick from, default `"0123456789abcdefghijklmnopqrstuvwxyz"`.
    """

    return ''.join(random.choice(alphabet) for _ in range(n))



if __name__ == "__main__":
    pass
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
"""


class JsonManipulator:
    """
    A utility to handle JSON-like object.  E.g. if you have a 
    JSON object o = {} and we want to set o["3"][5] = True, then
    we have to check if object o has property "3", if not it needs to
    create that property with the correct type (array, object, or some
    primitve), all the way down.  In the case of o["3"][5] we don't know
    whether [5] is accessing an object or an array.

    The syntax here is,

        a{}b{}c[]+

    Which would mean 

        obj["a"]["b"]["c"].append(...)
    
    """

    def __init__(self, obj = {}):
        self.obj = obj

    def get_obj(self):
        return self.obj

    def set_obj(self, obj):
        self.obj = obj

    def parse(self, path):
        in_object_access = False
        in_array_access = False
        buffer = ""
        parts = []
        for i in range(len(path)):
            symbol = path[i]

            if in_object_access:
                if symbol == "}":
                    in_object_access = False
                    buffer = buffer.strip()
                    assert len(buffer) == 0
                    parts += ["{}"]
                else:
                    buffer += symbol
            elif in_array_access:
                if symbol == "]":
                    in_array_access = False
                    buffer = buffer.strip()
                    assert len(buffer) == 0
                    parts += ["[]"]
                else:
                    buffer += symbol
            else:
                if symbol == "{":
                    in_object_access = True
                    buffer = buffer.strip()
                    if len(buffer) > 0:
                        parts += [buffer]
                        buffer = ""
                elif symbol == "[":
                    in_array_access = True
                    buffer = buffer.strip()
                    if len(buffer) > 0:
                        parts += [buffer]
                        buffer = ""
                else:
                    buffer += symbol
        
        buffer = buffer.strip()
        if len(buffer) > 0:
            parts += [buffer]
            buffer = ""
        
        for i in range(1, len(parts), 2):
            assert parts[i] == "{}" or parts[i] == "[]"

        return parts
        
    
    def get(self, path):
        # MODIFIED FROM set
        parts = self.parse(path)
        node = self.obj
        n = len(parts)
        # Access part
        for i in range(1, len(parts), 2):
            n_name = parts[i - 1]
            n_type = parts[i]
            if isinstance(node, dict):
                if n_type == "{}":
                    if n_name not in node:
                        node[n_name] = {}
                    node = node[n_name] 
                elif n_type == "[]":
                    if n_name not in node:
                        node[n_name] = []
                    node = node[n_name]
                else:
                    raise Exception("Error")
            elif isinstance(node, list):
                idx = None
                if n_name == "-" or n_name == "+":
                    if n_name == "-":
                        if n_type == "{}":
                            node = node[0]
                        elif n_type == "[]":
                            node = node[0]
                        else:
                            raise Exception("Error")
                        raise Exception("Not supported: -")
                    elif n_name == "+":
                        if n_type == "{}":
                            node = node[-1]
                        elif n_type == "[]":
                            node = node[-1]
                        else:
                            raise Exception("Error")
                    else:
                        raise Exception("Error")
                else:
                    idx = int(n_name)
                    if n_type == "{}":
                        node = node[idx]
                    elif n_type == "[]":
                        node = node[idx]
                    else:
                        raise Exception("Error")
            else:
                raise Exception("Error!")
        if n % 2 == 1:
            part = parts[-1]
            n_name = part
            if isinstance(node, dict):
                return node[n_name]
            elif isinstance(node, list):
                idx = None
                if n_name == "-" or n_name == "+":
                    if n_name == "-":
                        if n_type == "{}":
                            return node[0]
                        elif n_type == "[]":
                            return node[0]
                        else:
                            raise Exception("Error")
                    elif n_name == "+":
                        if n_type == "{}":
                            return node[-1]
                        elif n_type == "[]":
                            return node[-1]
                        else:
                            raise Exception("Error")
                    else:
                        raise Exception("Error")
                else:
                    idx = int(n_name)
                    if n_type == "{}":
                        return node[idx]
                    elif n_type == "[]":
                        return node[idx]
                    else:
                        raise Exception("Error")
        else:
            # Just tryin'...
            return node
    
    def set(self, path, value=None):
        parts = self.parse(path)
        node = self.obj
        n = len(parts)
        if n % 2 == 0 and value is not None:
            raise Exception("Value cannot be inserted: " + path)
        # Access part
        for i in range(1, len(parts), 2):
            n_name = parts[i - 1]
            n_type = parts[i]
            if isinstance(node, dict):
                if n_type == "{}":
                    if n_name not in node:
                        node[n_name] = {}
                    node = node[n_name] 
                elif n_type == "[]":
                    if n_name not in node:
                        node[n_name] = []
                    node = node[n_name]
                else:
                    raise Exception("Error")
            elif isinstance(node, list):
                idx = None
                if n_name == "-" or n_name == "+":
                    if n_name == "-":
                        if n_type == "{}":
                            node.insert(0, {})
                            node = node[0]
                        elif n_type == "[]":
                            node.insert(0, [])
                            node = node[0]
                        else:
                            raise Exception("Error")
                        raise Exception("Not supported: -")
                    elif n_name == "+":
                        if n_type == "{}":
                            node.append({})
                            node = node[-1]
                        elif n_type == "[]":
                            node.append([])
                            node = node[-1]
                        else:
                            raise Exception("Error")
                    else:
                        raise Exception("Error")
                else:
                    idx = int(n_name)
                    if n_type == "{}":
                        node = node[idx]
                    elif n_type == "[]":
                        node = node[idx]
                    else:
                        raise Exception("Error")
            else:
                raise Exception("Error!")
        if n % 2 == 1:
            part = parts[-1]
            n_name = part
            if isinstance(node, dict):
                node[n_name] = value
            elif isinstance(node, list):
                idx = None
                if n_name == "-" or n_name == "+":
                    if n_name == "-":
                        if n_type == "{}":
                            node.insert(0, value)
                        elif n_type == "[]":
                            node.insert(0, value)
                        else:
                            raise Exception("Error")
                    elif n_name == "+":
                        if n_type == "{}":
                            node.append(value)
                        elif n_type == "[]":
                            node.append(value)
                        else:
                            raise Exception("Error")
                    else:
                        raise Exception("Error")
                else:
                    idx = int(n_name)
                    if n_type == "{}":
                        node[idx] = value
                    elif n_type == "[]":
                        node[idx] = value
                    else:
                        raise Exception("Error")#!/usr/bin/env python3
# -*- coding: utf-8 -*-

from lib.utils import load_file_as_json, save_json_to_file, does_file_exist
from lib.json_manipulator import JsonManipulator

class Manifest(JsonManipulator):

    def __init__(self, filename=None, eager=False, obj={}):
        JsonManipulator.__init__(self, obj)
        self.filename = filename
        self.eager = eager

    def load(self, filename = None):
        if filename is not None:
            if does_file_exist(filename):
                self.obj = load_file_as_json(filename)
        elif self.filename is not None:
            if does_file_exist(self.filename):
                self.obj = load_file_as_json(self.filename)
        

    def save(self, filename = None):
        if filename is not None:
            save_json_to_file(filename, self.obj, overwrite=True)
        elif self.filename is not None:
            save_json_to_file(self.filename, self.obj, overwrite=True)
    
    def get(self, path):
        if self.eager:
            self.load(self.filename)
        return super(Manifest, self).get(path)
    
    def set(self, path, value=None):
        if self.eager:
            self.load(self.filename)
        super(Manifest, self).set(path, value)
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
TODO: epsilon should be a parameter for this class, and also whether
one wants to use Parallel Network.
"""
# Basic libraries
import numpy as np
import random
import time
import copy
import torch

# Recycled code
from pub_stomper_policy import Policy
from backgammon_game import Backgammon
from pub_stomper_basic_network_for_testing import BasicNetworkForTesting

# Dyna2 specific code
from psuedo_policy import PolicyPsuedo
from pub_stomper_agents.psuedo_agent import PsuedoAgent

amount_of_planning_games = 10
learning_rate = 0.005

class PolicyDyna2(Policy):

    def __init__(self, verbose=False, agent_cfg=None, imported=False):
        """
        Args:
            load_best (bool): default `False`
            verbose (bool): default `False`
            export (bool): default `False`
            agent_cfg: default `None`
            archive_name: default `None`.
        """
        if not agent_cfg:
            print('No cfg file bruh')

        Policy.__init__(self)
        self.agent_cfg = agent_cfg
        self.verbose = verbose
        self.after_state = 'null'
        self.permanent_net = BasicNetworkForTesting(verbose=verbose, agent_cfg=agent_cfg, imported=imported)
        self.transient_net = 'uninitialized'
        self.model_net = 'uninitialized'

    def winner(self, board):
        if board[28] > 14: return 1
        if board[29] > 14: return -1
        return 0

    def simulate_remainder_of_episode(self, board):
        while not self.winner(board):
            board = self.simulate_turn(board)
        return winner(board)

    def clone_neural_network(self, net, name):
        net.save_clone(name)
        clone = BasicNetworkForTesting(agent_cfg=self.agent_cfg)
        clone.load_clone(name)
        return clone

    def initialize_planning_phase(self):
        self.transient_net = self.clone_neural_network(self.permanent_net, 'kloni_doni')
        self.model_net = self.clone_neural_network(self.permanent_net, 'model')
        model_agent = PsuedoAgent(PolicyPsuedo(self.model_net))
        transient_agent = PsuedoAgent(PolicyPsuedo(self.transient_net))
        return model_agent, transient_agent

    def plan(self, board):
        time_when_planning_should_stop = time.time() * 1000 + 250
        model_agent, transient_agent = self.initialize_planning_phase()
        while time.time() * 1000 < time_when_planning_should_stop:
            copy_of_board = copy.deepcopy(board)
            game = Backgammon()
            game.reset()
            game.set_player_1(model_agent)
            game.set_player_2(transient_agent)
            reward = game.play(start_with_this_board=copy_of_board)
            transient_agent.add_reward(reward)

    def evaluate(self, possible_boards, board_copy):
        # variable to hold ratings
        move_ratings = []

        self.plan(board_copy)

        # predict win_rate of each possible after-state (possible_boards)
        for board in possible_boards:
            value_of_board = self.transient_net.predict(self.get_feature_vector(board))
            move_ratings.append(value_of_board)

        move = 0
        best_rating = move_ratings[0]
        for i, rating in enumerate(move_ratings):
            if best_rating < rating:
                best_rating = rating
                move = i

        # move = best_move if random.random() > self.epsilon else random.rand_int(len(possible_boards - 1)) # uncomment for e_greedy
        self.permanent_net.run_decision(self.get_feature_vector(possible_boards[move]))

        return move


    def save(self, save_as_best):
        return self.permanent_net.save(save_as_best=save_as_best)

    def load(self, filename):
        self.net.load(filename)

    def get_filename(self):
        """
        Returns the file name for this neural network attached to this instance.

        Returns:
            The file name of the neural network.
        """
        return self.net.filename

    def add_reward(self, reward):
        self.permanent_net.give_reward_to_nn(reward)

#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
This *IS* the neural network under consideration.
"""
import torch
import torch.nn as nn
import torch.nn.functional as Function
import torch.optim as Optimizer
from torch.autograd import Variable
import numpy as np
import datetime
from functools import reduce
from pathlib import Path
import copy
import os

from pub_stomper_lib.utils import load_file_as_json, get_random_string, rename_file_to_content_addressable, unarchive_archive, archive_files


dtype = torch.double
device = torch.device("cpu")
device = torch.device("cuda:0") # Uncomment this to run on GPU
default_filename = "_".join(str(datetime.datetime.now()).split(" "))


class PolicyGradientPlugin():
    # An add on for pub_stomper_basic_network_for_testing.py (why is this name still there)

    def make_filename_from_string(self, filename_root_string):
        # sets class-wide filename for exporting to files
        self.filename_value_function = './pub_stomper_repository/' + filename_root_string + "_valuefunction.pt"
        self.filename_value_optim  = './pub_stomper_repository/' + filename_root_string + "_valueoptim.pt"
        self.filename_pg_model    = './pub_stomper_repository/' + filename_root_string + "_pgmodel.pt"
        self.filename_pg_optim     = './pub_stomper_repository/' + filename_root_string + "_pgoptim.pt"

    def parse_json(self, agent_cfg):
        self.cfg_sgd = agent_cfg['cfg']['sgd']
        self.cfg_neural_network = agent_cfg['cfg']['neural_network']
        self.name = agent_cfg['name']
        self.filename = agent_cfg['cfg']['filename']

    def __init__(self, verbose=False, agent_cfg = None, imported=False, use_sigmoid=False):

        """
        Args:
            filename_of_network_to_bo_loaded: default `False`
            export: default `False` 
            verbose: default `False`
            agent_cfg: default `False`
            archive_name: default `None`
        """
        agent_cfg = agent_cfg if agent_cfg else default_agent_cfg
        self.parse_json(agent_cfg)

        # set up filenames for exporting
        self.make_filename_from_string(self.filename)

        output_layer = self.cfg_neural_network['output_layer']

        self.softmax_function = nn.Softmax()

        # a.k.a. w2
        self.value_function = nn.Sequential(nn.Linear(output_layer, 1))
        self.value_optim = torch.optim.SGD(self.value_function.parameters(), momentum = self.cfg_sgd['momentum'], lr = self.cfg_sgd['learning_rate'])

        # a.k.a. theta
        self.pg_model = nn.Sequential(nn.Linear(output_layer, 100), nn.Linear(100, 1))
        self.pg_optim = torch.optim.SGD(self.pg_model.parameters(), momentum = self.cfg_sgd['momentum'], lr = self.cfg_sgd['learning_rate_pg'])

        # If import if the config tells us to import it
        if imported:
            print('Loading...')
            self.load()
            return

    def save(self, save_as_best=False):
        if save_as_best:
            self.make_filename_from_string('nn_pg_best')

        print("Saving: " + self.filename_pg_model + ' and ' + self.filename_pg_optim)
        print("Saving: " + self.filename_value_function + ' and ' + self.filename_value_optim)

        # Save value function weights
        torch.save(self.value_function, self.filename_value_function)
        torch.save(self.value_optim.state_dict(), self.filename_value_optim)

        # Save pub_stomper_policy gradient weights
        torch.save(self.pg_model, self.filename_pg_model)
        torch.save(self.pg_optim.state_dict(), self.filename_pg_optim)

    def load(self):
        print("Loading: " + self.filename_value_function + ' and ' + self.filename_value_optim)

        # CHECK IF FILE EXISTS
        filenames = [
            self.filename_value_function,
            self.filename_value_optim,
            self.filename_pg_model,
            self.filename_pg_optim
        ]
        if not all(filename for filename in filenames):
            raise Exception('Did not find all models or optimizers, export at least once first: \n',
                            '   Edit ./pub_stomper_configs/agent_***.json so you have these: \n',
                            filenames)

        self.pg_model = torch.load(self.filename_pg_model)
        self.pg_optim = torch.optim.SGD(self.pg_model.parameters(), momentum = self.cfg_sgd['momentum'], lr = self.cfg_sgd['learning_rate'])
        self.pg_optim.load_state_dict(torch.load(self.filename_pg_optim))


        self.value_function = torch.load(self.filename_value_function)
        self.value_optim = torch.optim.SGD(self.value_function.parameters(), momentum = self.cfg_sgd['momentum'], lr = self.cfg_sgd['learning_rate'])
        self.value_optim.load_state_dict(torch.load(self.filename_value_optim))

        for parameter in self.value_function.parameters():
            print(parameter.size())

    def softmax(self, input_vectors, requires_grad=True):
        scores = list(map(lambda input: self.pg_model(input.detach()), input_vectors))
        return Function.softmax(torch.cat(scores))

    def value_function(self, input, requires_grad=True):
        return self.value_function.apply(input)

    def manually_update_value_function(self):
        self.value_optim.step()

    def manually_update_pg_model(self):
        self.pg_optim.step()

    def reset_grads(self):
        self.pg_optim.zero_grad()
        self.value_optim.zero_grad()
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
import numpy as np
import random

from pub_stomper_policy import Policy
from pub_stomper_basic_network_for_testing import BasicNetworkForTesting
from parallel_network import ParallelNetwork


class PolicyNeuralNetwork(Policy):

    def __init__(self, verbose=False, agent_cfg=None, imported=False, pub_stomper_policy_decision_function='argmax'):
        """
        Args:
            load_best (bool): default `False`
            verbose (bool): default `False`
            export (bool): default `False`
            agent_cfg: default `None`
            archive_name: default `None`.
        """
        self.pub_stomper_policy_decision_function = pub_stomper_policy_decision_function

        self.verbose = verbose
        self.net = BasicNetworkForTesting(verbose=verbose, agent_cfg=agent_cfg, imported=imported)

    def argmax(self, move_ratings):
        # get max value
        max = move_ratings[0]
        max_i = 0
        for i, move in enumerate(move_ratings):
            if move > max:
                max = move
                max_i = i
        return max_i

    def pub_stomper_policy_gradient(self, move_ratings):
        exponential_ratings = map(lambda move_rating: np.e ** move_rating)
        move = 0
        random_number = random.random()
        accumulator = 0
        for rating in exponential_ratings:
            accumulator += rating
            if accumulator > random_number:
                break
            move += 1

    def evaluate(self, possible_boards):
        """
        Evaluates the possible boards given to this method as an argument and
        returns a move.

        Args:
            possible_boards: possible boards

        Returns:
            A move.
        """
        # variable to hold ratings
        move_ratings = []

        # predict win_rate of each possible after-state (possible_boards)
        for board in possible_boards:
            value_of_board = self.net.predict(self.get_feature_vector(board))
            move_ratings.append(value_of_board)

        move = 0
        # move = best_move if random.random() > self.epsilon else random.rand_int(len(possible_boards - 1)) # uncomment for e_greedy
        self.net.run_decision(self.get_feature_vector(possible_boards[move]))

        return move

    def save(self, save_as_best=False):
        return self.net.save(save_as_best=save_as_best)

    def load(self, filename):
        self.net.load(filename)

    def get_filename(self):
        """
        Returns the file name for this neural network attached to this instance.

        Returns:
            The file name of the neural network.
        """
        return self.net.filename

    def add_reward(self, reward):
        # only necessary line in this function
        self.net.give_reward_to_nn(reward)

#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
TODO: epsilon should be a parameter for this class, and also whether
one wants to use Parallel Network.
"""
# Basic libraries
import numpy as np
import random
import torch

from torch.distributions.categorical import Categorical
from torch.distributions.multinomial import Multinomial

from pub_stomper_policy import Policy
from pub_stomper_basic_network_for_testing import BasicNetworkForTesting
from pub_stomper_policy_gradient_plugin import PolicyGradientPlugin

class PolicyPGNetwork(Policy):

    def __init__(self, verbose=False, agent_cfg=None, imported=False, pub_stomper_policy_decision_function='argmax'):
        """
        Args:
            load_best (bool): default `False`
            verbose (bool): default `False`
            export (bool): default `False`
            agent_cfg: default `None`
            archive_name: default `None`.
        """
        if not agent_cfg:
            print('No cfg file bruh')
        Policy.__init__(self)
        self.pub_stomper_policy_decision_function = pub_stomper_policy_decision_function
        self.saved_log_probabilities = []
        self.saved_value_estimations = []

        self.verbose = verbose
        self.net = BasicNetworkForTesting(verbose=verbose, agent_cfg=agent_cfg, imported=imported)
        self.pg_plugin = PolicyGradientPlugin(agent_cfg=agent_cfg, imported=imported)

    def argmax(self, move_ratings):
        # get max value
        max = move_ratings[0]
        max_i = 0
        for i, move in enumerate(move_ratings):
            if move > max:
                max = move
                max_i = i
        return max_i

    # initialize move storage
    # YOU ARE NEVER EMPTYING THIS STUFF

    def run_through_neural_network(self, possible_boards):
        last_layer_outputs = []
        for board in possible_boards:
            value_of_board = self.net.run_decision(self.get_feature_vector(board), save_predictions=False)
            layst_layer_outputs = last_layer_outputs.append(value_of_board)
        return last_layer_outputs


    def evaluate(self, possible_boards):

        # possible_boards -> neural network -> sigmoid -> last_layer_sigmoid
        last_layer_outputs = self.run_through_neural_network(possible_boards)
        # last_layer_sigmoid = list(map(lambda x: x.sigmoid(), last_layer_outputs))

        # Decide move and save log_prob for backward
        # We make sure not to affect the value fn with .detach()

        probs = self.pg_plugin.softmax(last_layer_outputs)
        distribution = Multinomial(1, probs)
        move = distribution.sample()
        self.saved_log_probabilities.append(distribution.log_prob(move))

        _, move = move.max(0)
        # calculate the value estimation and save for backward
        value_estimate = self.pg_plugin.value_function(last_layer_outputs[move])
        self.saved_value_estimations.append(value_estimate)
        return move

    def save(self, save_as_best=False):
        self.net.save(save_as_best=save_as_best)
        self.pg_plugin.save(save_as_best=save_as_best)

    def load(self, filename):
        self.net.load(filename)
        self.pg_plugin.load(filename)

    def get_filename(self):
        """
        Returns the file name for this neural network attached to this instance.

        Returns:
            The file name of the neural network.
        """
        return self.net.filename

    def add_reward(self, reward):
        td_n = 1
        episode_length = len(self.saved_value_estimations)
        values = torch.stack(self.saved_value_estimations).squeeze()
        values_no_grad = values.detach()
        # shift the values by td_n
        targets = torch.cat((values_no_grad[td_n:], (torch.ones(td_n) * reward)))
        # Squared error for value function
        loss = (targets - values).pow(2).sum()

        self.pg_plugin.reset_grads()
        self.net.manually_reset_grad()

        # Update the weights of value function
        loss.backward()
        self.net.manually_update_weights_of_network()
        self.pg_plugin.manually_update_value_function()

        # til ad optimize-a thetta tha tharf eg ad setja thetta i module
        # like this guy
        # https://github.com/pytorch/examples/blob/master/reinforcement_learning/reinforce.py#L90
        # Update the pub_stomper_policy gradient by maximizing this:
        rewards = torch.ones(episode_length) * reward
        # get the sum of the rewards * log_prob a.k.a. loss
        # Note that we put the (-) in front of rewards to do
        # gradient ascent instead of descent
        log_probs = torch.stack(self.saved_log_probabilities)
        loss2 = torch.dot(-rewards, log_probs)
        loss2.backward()
        self.pg_plugin.manually_update_pg_model()

        self.saved_log_probabilities = []
        self.saved_value_estimations = []
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
I think this class, `pub_stomper_policy`, should be extended.
"""

import numpy as np
import torch

# Extend this class to make a pub_stomper_policy to have all the feature_vector functions
class Policy():
    """
    A pub_stomper_policy.
    """

    def __init__(self):
        """
        Lalala
        """
        pass

    def get_tesauro_feature_vector(self, board):
        """
        This returns a feature vecture as is used by Tesauro in
        TD-Gammon.

        Args:
            board (ndarray): a backgammon board

        Returns:
            A feature vector.
        """
        main_board = board[1:25]
        jail1, jail2, off1, off2 = board[25], board[26], board[27], board[28]
        features = np.array([])

        # naum i feature vector af adalsvaedinu
        for position in main_board:
            vector = np.zeros(4)
            sign = -1 if position < 0 else 1
            for i in range(int(abs(position))):
                if i > 3:
                    vector[3] = sign * (abs(position) - 3) / 2
                    break
                vector[i] = position/abs(position)
            features = np.append(features, vector)

        # jail feature-ar
        jail_features = np.array([jail1, jail2]) * 0.5

        # features fyrir hversu margir eru borne off
        off_board_features = np.array([off1, off2]) * (0.066667)
        bias_vector = np.array([1, 1])
        features =  np.append(features, [jail_features, off_board_features, bias_vector])
        features = torch.from_numpy(features).float()
        features.requires_grad = True
        return features


    def get_feature_vector(self, board):
        """
        Returns the raw feature vector for the backgammon board `board`.

        Args:
            board (ndarray): a backgammon board

        Returns:
            A feature vector.
        """
        return self.hot_one(board)
        # return self.get_tesauro_feature_vector(self, board)

    def hot_one(self, board):
        features = np.array([])
        for position in board:
            vector = np.zeros(16)
            vector[int(position) - 1] = 1
            features = np.append(features, vector)
        features = torch.from_numpy(features).float()
        features.requires_grad = True
        return features


    # expand board -> 464 vector
    def get_raw_data(self, board):
        """
        Returns the raw feature vector for the backgammon board `board`.

        Args:
            board (ndarray): a backgammon board

        Returns:
            A feature vector.
        """
        features = np.array([])
        for position in board:
            vector = np.zeros(16)
            for i in range(int(position)):
                vector[i] = 1
            features = np.append(features, vector)
        features = torch.from_numpy(features).float()
        features.requires_grad = True
        return features

    # Override these methods
    def add_reward(self, reward):
        raise Exception("Reward function not set")

    def evaluate(self, board):
        raise Exception("Evaluation function not set")

    def get_filename(self):
        raise Exception("File name not set")
from pathlib import Path
import numpy as np


class Statistic():
    # notum til ad skoda hvort tauganetid er consistently betra

    # likur a ad nn se betra eru tha 98.9% i hvert skipti sem er tekkad
    # vid tekkum hver 100 skipti svo vid ovart setjum ekki jafn gott/verra net
    # i stadinn fyrir thad besta (ef thad winnur 51% skipta tha verdur thad
    # nogu heppid a ~2000 leikja fresti)
    goal_win_rate = 0.537


    last_5000_wins = np.zeros(1000)
    last_500_wins = np.zeros(500)
    winners = [0, 0]
    games_played = 0
    highest_win_rate = 0
    win_rate = 0
    verbose = False

    def __init__(self, agent, verbose=False):
        self.agent = agent
        if verbose:
            self.verbose = True

    def two_digits(self, double_number):
        return "{0:.2f}".format(double_number)

    def update_win_rate(self, winner):
        win = 1 if winner > 0 else 0
        self.last_500_wins[self.games_played % 500] = win
        self.last_5000_wins[self.games_played % 5000] = win
        self.win_rate = np.sum(self.last_500_wins) / 5
        if self.win_rate > self.highest_win_rate:
            self.highest_win_rate = self.win_rate

    def nn_is_better(self):
        if np.sum(self.last_5000_wins) / 5000 > self.goal_win_rate:
            return True
        return False

    def add_win(self, winner, verbose=False):
        self.games_played += 1
        self.update_win_rate(winner)
        i = 0 if winner == 1 else 1
        self. winners[i] += 1
        if self.verbose:
            self.verbose_print()

    def verbose_print(self):
        string =      "Player 1 : Player 2 : Total     "
        string +=     str(self.winners[0]) + " : " + str(self.winners[1]) + " : " + str(self.games_played)
        string +=     "        moving average 500:   "
        string +=     str(self.win_rate) + "%"
        string +=     " (max - stddev = "
        string +=     str(self.two_digits(self.highest_win_rate - 2)) + "%), std-dev of this is ~2%"
        print(string)

    # Print results out to a file (every 100 games)
    # agent object needs to have a get_filename() method!
    def output_result(self):
        """
        Save something from `do_default()`.
        """
        filename = "results/" + self.agent.get_filename() + "_result.pt"
        Path(filename).touch()
        file = open(filename, "w")
        file.write("Highest win rate last 500: " + str(self.highest_win_rate) + "\n")
        file.write("End win rate: " +  str(self.win_rate) + "\n")
        file.write("Wins: " + str(self.winners[0]) + "\n")
        file.write("Loses: " + str(self.winners[1]) + "\n")
        file.write("Games played: " + str(self.games_played) + "\n")
        file.close()

import matplotlib
import matplotlib.pyplot as plt
import numpy as np
import sys


def get_wins(arg_number):
    print(sys.argv[arg_number])
    data = open(sys.argv[arg_number])
    data = filter(lambda line: line.startswith('Player'), data)
    lol = True
    win_history = []
    for line in data:
        numbers = [int(string) for string in line.split() if string.isdigit()]
        wins = numbers[2]
        win_history.append(wins)
    return win_history

def calculate_moving_average(arg_number):
    last_100_wins = np.zeros(100)
    last = 0
    moving_average = np.array([])
    for i ,n in enumerate(get_wins(arg_number)):
        if last == n:
            last_100_wins[i % 100] = -1
        else:
            last_100_wins[i % 100] = 1
        last = n
        moving_average = np.append(moving_average, last_100_wins.sum() / 100)
    return moving_average

filenames = sys.argv[1:]
figure, axis = plt.subplots()
axis.grid()

def plot(arg_number):
    y = calculate_moving_average(arg_number)
    x = np.array([i + 1 for i in range(1000)])
    y = y[-900::5]
    x = x[-900::5]
    label = " ".join(sys.argv[arg_number].split("_"))
    axis.plot(x, y, label=label)

for i in range(len(filenames)):
    plot(i + 1)

axis.legend()
plt.show()

import matplotlib
import matplotlib.pyplot as plt
import numpy as np
import sys


def get_wins(arg_number):
    print(sys.argv[arg_number])
    data = open(sys.argv[arg_number])
    data = filter(lambda line: line.startswith('Player'), data)
    lol = True
    win_history = []
    for line in data:
        numbers = [int(string) for string in line.split() if string.isdigit()]
        wins = numbers[2]
        win_history.append(wins)
    return win_history

def calculate_moving_average(arg_number):
    last_100_wins = np.zeros(100)
    last = 0
    moving_average = np.array([])
    for i ,n in enumerate(get_wins(arg_number)):
        if last == n:
            last_100_wins[i % 100] = -1
        else:
            last_100_wins[i % 100] = 1
        last = n
        moving_average = np.append(moving_average, last_100_wins.sum() / 100)
    return moving_average

filenames = sys.argv[1:]
figure, axis = plt.subplots()
axis.grid()

def plot(arg_number):
    y = calculate_moving_average(arg_number)
    x = np.array([i + 1 for i in range(1000)])
    y = y[-900::5]
    x = x[-900::5]
    label = " ".join(sys.argv[arg_number].split("_"))
    axis.plot(x, y, label=label)

for i in range(len(filenames)):
    plot(i + 1)

axis.legend()
plt.show()
